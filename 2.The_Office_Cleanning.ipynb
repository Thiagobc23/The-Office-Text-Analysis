{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "This notebook will go trough the cleaning process of the file The_Office.csv, extracted with The_Office_Scraper.py.\n",
    "\n",
    "The main objective is make sure the character names are correct, without typos, mismatches and errors in general.\n",
    "\n",
    "## Prepare Enviorment\n",
    "\n",
    "The libraries required to run this notebook are Pandas, Numpy, VaderSentiment, and NLTK.\n",
    "\n",
    "* this notebook will also make use of requests, json, and re (regular expressions), those are standard libraries in python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (1.16.2)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# install required libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install vaderSentiment\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>char</th>\n",
       "      <th>text</th>\n",
       "      <th>ep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As you may be aware our board is experiencing ...</td>\n",
       "      <td>https://www.facebook.com/foreverdreaming.org/</td>\n",
       "      <td>Board Updates: Please Read 8/26/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>If you would like to help edit any of our tran...</td>\n",
       "      <td>)</td>\n",
       "      <td>Board Updates: Please Read 8/26/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Michael</td>\n",
       "      <td>All right Jim. Your quarterlies look very goo...</td>\n",
       "      <td>01x01 - Pilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>01x01 - Pilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Michael</td>\n",
       "      <td>So you've come to the master for guidance? Is...</td>\n",
       "      <td>01x01 - Pilot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               char  \\\n",
       "0   0  As you may be aware our board is experiencing ...   \n",
       "1   1  If you would like to help edit any of our tran...   \n",
       "2   2                                            Michael   \n",
       "3   3                                                Jim   \n",
       "4   4                                            Michael   \n",
       "\n",
       "                                                text  \\\n",
       "0     https://www.facebook.com/foreverdreaming.org/    \n",
       "1                                                  )   \n",
       "2   All right Jim. Your quarterlies look very goo...   \n",
       "3         Oh, I told you. I couldn't close it. So...   \n",
       "4   So you've come to the master for guidance? Is...   \n",
       "\n",
       "                                   ep  \n",
       "0  Board Updates: Please Read 8/26/19  \n",
       "1  Board Updates: Please Read 8/26/19  \n",
       "2                       01x01 - Pilot  \n",
       "3                       01x01 - Pilot  \n",
       "4                       01x01 - Pilot  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "root_path = ''\n",
    "df = pd.read_csv(root_path+'the_office.csv', sep=';', encoding='utf-16')\n",
    "df.columns = ['id','char','text','ep']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Characters\n",
    "Some dialogs had more than one characther talking the same thing at the same time, those were found in different ways like listed bellow.  \n",
    "  \n",
    "        char X and char Y;  \n",
    "        char X & char Y;  \n",
    "        char X, char Y and char Z;  \n",
    "        char X, Y, Z;  \n",
    "        char X/ char Y;  \n",
    "        \n",
    "The following script will break up those records in separate characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_id = []\n",
    "n_char = []\n",
    "n_text = []\n",
    "n_ep = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # trim\n",
    "    name = re.sub(\"[\\[].*?[\\]]\", \"\", row.char).strip()\n",
    "    name = name.replace('\"','').replace(' together','')\n",
    "    #separate characters\n",
    "    #and\n",
    "    if ' & ' in name:\n",
    "        name = name.replace(' & ', ' and ')\n",
    "    if ' and ' in name:\n",
    "        temp = name.split(' and ')\n",
    "        name = temp[0]\n",
    "        if name.endswith(','):\n",
    "            name = name[:-1]\n",
    "        \n",
    "        n_id.append(row.id)\n",
    "        n_char.append(temp[1])\n",
    "        n_text.append(row.text)\n",
    "        n_ep.append(row.ep)\n",
    "    #comma\n",
    "    if ',' in name:\n",
    "        names = name.split(', ')\n",
    "        name = names[0]\n",
    "        for value in names[1:]:\n",
    "            n_id.append(row.id)\n",
    "            n_char.append(value)\n",
    "            n_text.append(row.text)\n",
    "            n_ep.append(row.ep)\n",
    "    #slash\n",
    "    if '/' in name and name != 'DunMiff/sys':\n",
    "        names = name.split('/')\n",
    "        name = names[0]\n",
    "        for value in names[1:]:\n",
    "            n_id.append(row.id)\n",
    "            n_char.append(value)\n",
    "            n_text.append(row.text)\n",
    "            n_ep.append(row.ep)\n",
    "\n",
    "    df.at[i,'char'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = pd.DataFrame(n_id)\n",
    "df_add.columns = ['id']\n",
    "df_add['char'] = n_char\n",
    "df_add['text'] = n_text\n",
    "df_add['ep'] = n_ep\n",
    "\n",
    "df = df.append(df_add, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>char</th>\n",
       "      <th>ep</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60314</th>\n",
       "      <td>177</td>\n",
       "      <td>Vance Refrigeration</td>\n",
       "      <td>09x20 - Paper Airplane</td>\n",
       "      <td>59044</td>\n",
       "      <td>You can do it baby!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60315</th>\n",
       "      <td>178</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59615</td>\n",
       "      <td>Kevin, what?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60316</th>\n",
       "      <td>179</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59694</td>\n",
       "      <td>Sea horse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60317</th>\n",
       "      <td>180</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59696</td>\n",
       "      <td>Say that? Uncanny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60318</th>\n",
       "      <td>181</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59817</td>\n",
       "      <td>Shhh!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                 char                      ep     id  \\\n",
       "60314    177  Vance Refrigeration  09x20 - Paper Airplane  59044   \n",
       "60315    178                Oscar      09x22/23 - A.A.R.M  59615   \n",
       "60316    179               Dwight      09x22/23 - A.A.R.M  59694   \n",
       "60317    180               Dwight      09x22/23 - A.A.R.M  59696   \n",
       "60318    181                Oscar      09x22/23 - A.A.R.M  59817   \n",
       "\n",
       "                       text  \n",
       "60314   You can do it baby!  \n",
       "60315          Kevin, what?  \n",
       "60316            Sea horse.  \n",
       "60317    Say that? Uncanny.  \n",
       "60318                 Shhh!  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Names\n",
    "The characters were analysed in groups and them individually to make sure they were correctly recorded, three blocks of code that can be found at the end of this notebook were used to analyse the characters.  \n",
    "This website was used for research about the characters: https://theoffice.fandom.com/wiki/Main_Page\n",
    "  \n",
    "The result of this research was a .json file containing a dictionary with the mismatching values and the correct values.\n",
    "  \n",
    "Besides the corrections.json, some characters have similar names so the episode name was considered for separate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('corrections.json')\n",
    "corrections_json = file.read()\n",
    "corrections = json.loads(corrections_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    name=str(row.char)\n",
    "    # rename\n",
    "    if name in corrections:\n",
    "        name = corrections[name]\n",
    "    #roberts\n",
    "    elif name == 'Robert':\n",
    "        if str(row.ep) in ['07x11/12 - Classy Christmas (Parts 1&2)', '09x16 - Moving On']:\n",
    "            name = 'Robert Lipton'\n",
    "        else:\n",
    "            name = 'Robert California'\n",
    "    #davids\n",
    "    elif name == 'David':\n",
    "        if row.ep is '07x14 - The Seminar':\n",
    "            name = 'David Brent'\n",
    "        else:\n",
    "            name = 'David Wallace'\n",
    "    #Samuel and Samuel L. Chang(Dwight)\n",
    "    elif name=='Samuel' and str(row.ep) is '07x17 - Threat Level Midnight':\n",
    "        name = 'Dwight'\n",
    "    \n",
    "    elif name=='Nick' and str(row.ep) is '04x07/08 - Money (Parts 1&2)':\n",
    "        name = 'Nick Figaro'\n",
    "    \n",
    "    df.at[i,'name'] = str(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>char</th>\n",
       "      <th>ep</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60314</th>\n",
       "      <td>177</td>\n",
       "      <td>Vance Refrigeration</td>\n",
       "      <td>09x20 - Paper Airplane</td>\n",
       "      <td>59044</td>\n",
       "      <td>You can do it baby!</td>\n",
       "      <td>Vance Refrigeration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60315</th>\n",
       "      <td>178</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59615</td>\n",
       "      <td>Kevin, what?</td>\n",
       "      <td>Oscar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60316</th>\n",
       "      <td>179</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59694</td>\n",
       "      <td>Sea horse.</td>\n",
       "      <td>Dwight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60317</th>\n",
       "      <td>180</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59696</td>\n",
       "      <td>Say that? Uncanny.</td>\n",
       "      <td>Dwight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60318</th>\n",
       "      <td>181</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59817</td>\n",
       "      <td>Shhh!</td>\n",
       "      <td>Oscar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                 char                      ep     id  \\\n",
       "60314    177  Vance Refrigeration  09x20 - Paper Airplane  59044   \n",
       "60315    178                Oscar      09x22/23 - A.A.R.M  59615   \n",
       "60316    179               Dwight      09x22/23 - A.A.R.M  59694   \n",
       "60317    180               Dwight      09x22/23 - A.A.R.M  59696   \n",
       "60318    181                Oscar      09x22/23 - A.A.R.M  59817   \n",
       "\n",
       "                       text                 name  \n",
       "60314   You can do it baby!  Vance Refrigeration  \n",
       "60315          Kevin, what?                Oscar  \n",
       "60316            Sea horse.               Dwight  \n",
       "60317    Say that? Uncanny.               Dwight  \n",
       "60318                 Shhh!                Oscar  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Garbage\n",
    "As much as the scrapper avoided collecting unrelated data, some couldn't be identified at that part of the process so we need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ep = ['01x99 - Deleted Scenes from Season 1',\n",
    "             '02x99 - Deleted Scenes from Season 2',\n",
    "             '03x99 - Deleted Scenes from Season 3',\n",
    "             '04x99 - Deleted Scenes from Season 4',\n",
    "             '05x99 - Deleted Scenes from Season 5',\n",
    "             '08x99 - Deleted Scenes from Season 8',\n",
    "             'Board Updates: Please Read 8/26/19',\n",
    "             '06x00 - Subtle Sexuality Webisodes 1-3',\n",
    "             '07x00 - The 3rd Floor Webisodes 1-3',\n",
    "             '05x30 - Gag Reel',\n",
    "             \"05x00 - Kevin's Loan Webisodes 1-4\",\n",
    "             '03x00 - The Accountants Webisodes 1-10']\n",
    "# values I couldn't identify or classify\n",
    "remove_c = ['8', \"I'm gonna try to get to bed by 8\", 'Boom Box',\n",
    "            \"Vance Refrigeration\", 'Both', 'Song', 'song', \"Oscar's Computer\",\n",
    "            \"Erin's Cell Phone\", \"Ryan's Voicemail\", \"Jim's voicemail\",\n",
    "            'Automated phone voice', 'Voice on CD player', 'Robotic Voice',\n",
    "            'Voicemail', 'GPS', 'Offscreen', 'Computron','DunMiff/sys',\n",
    "            'Off-camera', 'Video']\n",
    "# drop above listed records\n",
    "df = df.drop(df[df['ep'].isin(remove_ep)].index)\n",
    "df = df.drop(df[df['char'].isin(remove_c)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>char</th>\n",
       "      <th>ep</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60313</th>\n",
       "      <td>176</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x18 - Promos</td>\n",
       "      <td>58614</td>\n",
       "      <td>Hi honey!</td>\n",
       "      <td>Oscar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60315</th>\n",
       "      <td>178</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59615</td>\n",
       "      <td>Kevin, what?</td>\n",
       "      <td>Oscar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60316</th>\n",
       "      <td>179</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59694</td>\n",
       "      <td>Sea horse.</td>\n",
       "      <td>Dwight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60317</th>\n",
       "      <td>180</td>\n",
       "      <td>Dwight</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59696</td>\n",
       "      <td>Say that? Uncanny.</td>\n",
       "      <td>Dwight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60318</th>\n",
       "      <td>181</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>09x22/23 - A.A.R.M</td>\n",
       "      <td>59817</td>\n",
       "      <td>Shhh!</td>\n",
       "      <td>Oscar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    char                  ep     id                 text    name\n",
       "60313    176   Oscar      09x18 - Promos  58614            Hi honey!   Oscar\n",
       "60315    178   Oscar  09x22/23 - A.A.R.M  59615         Kevin, what?   Oscar\n",
       "60316    179  Dwight  09x22/23 - A.A.R.M  59694           Sea horse.  Dwight\n",
       "60317    180  Dwight  09x22/23 - A.A.R.M  59696   Say that? Uncanny.  Dwight\n",
       "60318    181   Oscar  09x22/23 - A.A.R.M  59817                Shhh!   Oscar"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_txt=[]\n",
    "for i, row in df.iterrows():\n",
    "    txt = str(row.text)\n",
    "    if '  ' in txt:\n",
    "        txt = txt.replace('  ',' ').strip()\n",
    "    # unmask some words\n",
    "    if 'v*g1n*' in txt:\n",
    "        txt = txt.replace('v*g1n*', 'vagina')\n",
    "    if 's*x' in txt:\n",
    "        txt = txt.replace('s*x', 'sex')\n",
    "    if 'f***ing' in txt:\n",
    "        txt = txt.replace('f***ing', 'fucking')    \n",
    "    \n",
    "    clean_txt.append(txt)\n",
    "    \n",
    "df['text'] = clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>char</th>\n",
       "      <th>ep</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60132</th>\n",
       "      <td>60132</td>\n",
       "      <td>Creed</td>\n",
       "      <td>09x24/25 - Finale</td>\n",
       "      <td>60547</td>\n",
       "      <td>It all seems so very arbitrary. I applied for ...</td>\n",
       "      <td>Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60133</th>\n",
       "      <td>60133</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>09x24/25 - Finale</td>\n",
       "      <td>60548</td>\n",
       "      <td>I just feel lucky that I got a chance to shar...</td>\n",
       "      <td>Meredith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60134</th>\n",
       "      <td>60134</td>\n",
       "      <td>Phyllis</td>\n",
       "      <td>09x24/25 - Finale</td>\n",
       "      <td>60549</td>\n",
       "      <td>I'm happy that this was all filmed so I can r...</td>\n",
       "      <td>Phyllis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60135</th>\n",
       "      <td>60135</td>\n",
       "      <td>Jim</td>\n",
       "      <td>09x24/25 - Finale</td>\n",
       "      <td>60550</td>\n",
       "      <td>I sold paper at this company for 12 years. My...</td>\n",
       "      <td>Jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60136</th>\n",
       "      <td>60136</td>\n",
       "      <td>Pam</td>\n",
       "      <td>09x24/25 - Finale</td>\n",
       "      <td>60551</td>\n",
       "      <td>I thought it was weird when you picked us to ...</td>\n",
       "      <td>Pam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      char                 ep     id  \\\n",
       "60132  60132     Creed  09x24/25 - Finale  60547   \n",
       "60133  60133  Meredith  09x24/25 - Finale  60548   \n",
       "60134  60134   Phyllis  09x24/25 - Finale  60549   \n",
       "60135  60135       Jim  09x24/25 - Finale  60550   \n",
       "60136  60136       Pam  09x24/25 - Finale  60551   \n",
       "\n",
       "                                                    text      name  \n",
       "60132  It all seems so very arbitrary. I applied for ...     Creed  \n",
       "60133   I just feel lucky that I got a chance to shar...  Meredith  \n",
       "60134   I'm happy that this was all filmed so I can r...   Phyllis  \n",
       "60135   I sold paper at this company for 12 years. My...       Jim  \n",
       "60136   I thought it was weird when you picked us to ...       Pam  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='id', inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Episode Field\n",
    "The episode name contains the episode number, the season number and the actual episode name. the bellow script will split them in three different fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_number=[]\n",
    "ep_name=[]\n",
    "season=[]\n",
    "for i, row in df.iterrows():\n",
    "    temp = row.ep.split(' - ')\n",
    "    ep_name.append(temp[-1])\n",
    "    temp = temp[0].split('x')\n",
    "    ep_number.append(temp[-1])\n",
    "    season.append(temp[0])\n",
    "\n",
    "df['episode_name']=ep_name\n",
    "df['episode_number']=ep_number\n",
    "df['season']=season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean episode names\n",
    "  \n",
    "### Separating episodes\n",
    "Some episodes were grouped in parts one and two, to separate them I had to watch the beggining of the episodes listed as 'part 2', taking note of the character who said the first dialog and the content of this dialog. \n",
    "Those were then used to separate the episodes where everything bellow the id of those dialogs are 'part 1' and everything above it is 'part 2'\n",
    "\n",
    "### Correcting names\n",
    "Some of the episodes names were also corrected to match the names on the IMDB dataset.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if row.episode_name == 'Niagara (Parts 1&2)':\n",
    "        if row.id < 32435:\n",
    "            df.at[i,'episode_name'] = 'Niagara: Part 1'\n",
    "            df.at[i,'episode_number'] = '04'\n",
    "        else:\n",
    "            df.at[i,'episode_name'] = 'Niagara: Part 2'\n",
    "            df.at[i,'episode_number'] = '05'\n",
    "    elif row.episode_name == 'The Delivery (Parts 1&2)':\n",
    "        if row.id < 36124:\n",
    "            df.at[i,'episode_name'] = 'The Delivery: Part 1'\n",
    "            df.at[i,'episode_number'] = '17'\n",
    "        else:\n",
    "            df.at[i,'episode_name'] = 'The Delivery: Part 2'\n",
    "            df.at[i,'episode_number'] = '18'\n",
    "            \n",
    "    # Correct some names\n",
    "    elif row.episode_name == 'Lecture Circuit (Part 1)':\n",
    "        df.at[i,'episode_name'] = 'Lecture Circuit: Part 1'\n",
    "        \n",
    "    elif row.episode_name == 'Lecture Circuit (Part 2)':\n",
    "        df.at[i,'episode_name'] = 'Lecture Circuit: Part 2'\n",
    "        \n",
    "    elif row.episode_name == 'Boys & Girls':\n",
    "        df.at[i,'episode_name'] = 'Boys and Girls'\n",
    "    \n",
    "    elif row.episode_name == 'A.A.R.M':\n",
    "        df.at[i,'episode_name'] = 'A.A.R.M.'\n",
    "        \n",
    "    elif row.episode_name == 's*x Ed':\n",
    "        df.at[i,'episode_name'] = 'Sex ED'\n",
    "        \n",
    "    elif row.episode_name == 'The Manager and the Salesman':\n",
    "        df.at[i,'episode_name'] = 'Manager and Salesman'\n",
    "    \n",
    "    elif row.episode_name in ['The Michael Scott Paper Company', 'The New Guys']:\n",
    "        df.at[i,'episode_name'] = row.episode_name[4:]    \n",
    "        \n",
    "    elif ' (Parts 1&2)' in row.episode_name:\n",
    "        df.at[i,'episode_name'] = row.episode_name.replace(' (Parts 1&2)','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last details\n",
    "Build a dataframe to be saved, remove characters identified as random people and add an id field to uniquely identify episodes and seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[['id', 'text', 'name', 'episode_name', 'episode_number', 'season']]\n",
    "# drop Random People\n",
    "result = result[result['name'] != 'Random People']\n",
    "# episode_name to upper case\n",
    "result['episode_name'] = [x.upper() for x in result['episode_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>season</th>\n",
       "      <th>ep_seas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All right Jim. Your quarterlies look very goo...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>So you've come to the master for guidance? Is...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text     name  \\\n",
       "2   2   All right Jim. Your quarterlies look very goo...  Michael   \n",
       "3   3         Oh, I told you. I couldn't close it. So...      Jim   \n",
       "4   4   So you've come to the master for guidance? Is...  Michael   \n",
       "5   5         Actually, you called me in here, but yeah.      Jim   \n",
       "6   6    All right. Well, let me show you how it's done.  Michael   \n",
       "\n",
       "  episode_name episode_number season ep_seas  \n",
       "2        PILOT             01     01   01-01  \n",
       "3        PILOT             01     01   01-01  \n",
       "4        PILOT             01     01   01-01  \n",
       "5        PILOT             01     01   01-01  \n",
       "6        PILOT             01     01   01-01  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a 'episode - season' field to handle unique episodes \n",
    "ep_seas = []\n",
    "for i, row in result.iterrows():\n",
    "    ep_seas.append(str(row['season'])+'-'+str(row['episode_number']))\n",
    "\n",
    "result['ep_seas'] = ep_seas\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *OPTIONAL - Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(root_path+'the_office_clean.csv', sep=';', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53847 entries, 2 to 60136\n",
      "Data columns (total 7 columns):\n",
      "id                53847 non-null int64\n",
      "text              53847 non-null object\n",
      "name              53847 non-null object\n",
      "episode_name      53847 non-null object\n",
      "episode_number    53847 non-null object\n",
      "season            53847 non-null object\n",
      "ep_seas           53847 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = result.copy()\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "\n",
    "Two functions will be used to create a second version of the text, a cleaner version without double spaces, punctuations, special characters and stop-words\n",
    "\n",
    "*According to [yourdictionary.com](https://www.yourdictionary.com/stop-word), a stop-word definition is:  \n",
    "    \n",
    "    Noun  \n",
    "    (computing) a word, usually one of a series in a stop list, that is to be ignored by a search engine etc\n",
    "    \n",
    "In this case, those are words without much meaning. So they'll be ignored in some parts of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dialog(s):\n",
    "    # replace special characters with space, remove underlines \n",
    "    # replace blank spaces with single blank space\n",
    "    clean = re.sub('[^\\w\\s]', '', s)\n",
    "    clean = re.sub('_', '', clean)\n",
    "    clean = re.sub('\\s+', ' ', clean)\n",
    "    clean = clean.lower()\n",
    "    return clean\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words_ext = ['na', 'da', 'dot', 'doo', 'a-wimowheh', 'parum', 'pum']\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    i = []\n",
    "    for word in words: \n",
    "        if word not in stop_words and word not in stop_words_ext: \n",
    "            i.append(word) \n",
    "    return ' '.join(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "The clean texts are then tokenized into both words and sentences, and their respective tokens are counted and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token, sent_qty, word_token, word_qty, clean_txt = [],[],[],[],[]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # build tokens\n",
    "    tokenized_text = sent_tokenize(str(row.text))\n",
    "    tokenized_word = word_tokenize(clean_dialog(str(row.text)))\n",
    "    # append to lists\n",
    "    sent_token.append(tokenized_text)\n",
    "    sent_qty.append(len(tokenized_text))\n",
    "    word_token.append(tokenized_word)\n",
    "    word_qty.append(len(tokenized_word))\n",
    "    clean_txt.append(remove_stopwords(tokenized_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The sentiment analysis was performed with VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "VADER uses a dictionary to assign scores to the words, besides that it uses the position of the words and punctuation to score the document with the proportion of each sentiment contained on it. Those sentiments are named negative, positive and neutral.\n",
    "\n",
    "After getting the proportions for each sentiment VADER also calculates a compound. The compound is basically a normalized sum of all proportions, goind from -1 (completely negative) to 1 (completely positive).\n",
    "\n",
    "Some of the semantic contexts considered by VADER are:\n",
    "\n",
    "    Conjunctions - E.g.: 'I like your X, but your Y is very bad';\n",
    "    Negation Flips - E.g: 'This is not really the greatest';\n",
    "    Degrees - E.g: 'This is good' vs 'This is extremely good';\n",
    "    Capitalization - E.g: 'this is GREAT' vs 'this is great';\n",
    "    Punctuation - E.g: 'this is great!!!' vs 'this is great';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis with Vader\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "neg, neu, pos, com = [], [], [], []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # generate polarity score\n",
    "    score = analyser.polarity_scores(str(row.text))\n",
    "    # append to lists\n",
    "    neg.append(score.get('neg'))\n",
    "    neu.append(score.get('neu'))\n",
    "    pos.append(score.get('pos'))\n",
    "    com.append(score.get('compound'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data\n",
    "\n",
    "The dataframe is extended with the fields:\n",
    "    \n",
    "    clean text;\n",
    "    sentences (tokens);\n",
    "    words (tokens);\n",
    "    sentences quantity (amount of sentences in a dialog);\n",
    "    words quantity (amount of words in a dialog);\n",
    "    negative (negative score for the dialog);\n",
    "    positive (positive score for the dialog);\n",
    "    neutral (neutral score for the dialog);\n",
    "    compound (overall compound score for the dialog);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>season</th>\n",
       "      <th>ep_seas</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences_qty</th>\n",
       "      <th>words_qty</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All right Jim. Your quarterlies look very goo...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "      <td>right jim quarterlies look good things library</td>\n",
       "      <td>[ All right Jim., Your quarterlies look very g...</td>\n",
       "      <td>[all, right, jim, your, quarterlies, look, ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "      <td>oh told couldnt close</td>\n",
       "      <td>[ Oh, I told you., I couldn't close it., So...]</td>\n",
       "      <td>[oh, i, told, you, i, couldnt, close, it, so]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>So you've come to the master for guidance? Is...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "      <td>youve come master guidance youre saying grassh...</td>\n",
       "      <td>[ So you've come to the master for guidance?, ...</td>\n",
       "      <td>[so, youve, come, to, the, master, for, guidan...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "      <td>actually called yeah</td>\n",
       "      <td>[ Actually, you called me in here, but yeah.]</td>\n",
       "      <td>[actually, you, called, me, in, here, but, yeah]</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01-01</td>\n",
       "      <td>right well let show done</td>\n",
       "      <td>[ All right., Well, let me show you how it's d...</td>\n",
       "      <td>[all, right, well, let, me, show, you, how, it...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.2732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text     name  \\\n",
       "2   2   All right Jim. Your quarterlies look very goo...  Michael   \n",
       "3   3         Oh, I told you. I couldn't close it. So...      Jim   \n",
       "4   4   So you've come to the master for guidance? Is...  Michael   \n",
       "5   5         Actually, you called me in here, but yeah.      Jim   \n",
       "6   6    All right. Well, let me show you how it's done.  Michael   \n",
       "\n",
       "  episode_name episode_number season ep_seas  \\\n",
       "2        PILOT             01     01   01-01   \n",
       "3        PILOT             01     01   01-01   \n",
       "4        PILOT             01     01   01-01   \n",
       "5        PILOT             01     01   01-01   \n",
       "6        PILOT             01     01   01-01   \n",
       "\n",
       "                                           clean_txt  \\\n",
       "2     right jim quarterlies look good things library   \n",
       "3                              oh told couldnt close   \n",
       "4  youve come master guidance youre saying grassh...   \n",
       "5                               actually called yeah   \n",
       "6                           right well let show done   \n",
       "\n",
       "                                           sentences  \\\n",
       "2  [ All right Jim., Your quarterlies look very g...   \n",
       "3    [ Oh, I told you., I couldn't close it., So...]   \n",
       "4  [ So you've come to the master for guidance?, ...   \n",
       "5      [ Actually, you called me in here, but yeah.]   \n",
       "6  [ All right., Well, let me show you how it's d...   \n",
       "\n",
       "                                               words  sentences_qty  \\\n",
       "2  [all, right, jim, your, quarterlies, look, ver...              3   \n",
       "3      [oh, i, told, you, i, couldnt, close, it, so]              3   \n",
       "4  [so, youve, come, to, the, master, for, guidan...              2   \n",
       "5   [actually, you, called, me, in, here, but, yeah]              1   \n",
       "6  [all, right, well, let, me, show, you, how, it...              2   \n",
       "\n",
       "   words_qty  negative  neutral  positive  compound  \n",
       "2         14       0.0    0.803     0.197    0.4927  \n",
       "3          9       0.0    1.000     0.000    0.0000  \n",
       "4         14       0.0    1.000     0.000    0.0000  \n",
       "5          8       0.0    0.714     0.286    0.4215  \n",
       "6         10       0.0    0.811     0.189    0.2732  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new features to dataframe\n",
    "df['clean_txt'] = clean_txt\n",
    "df['sentences'] = sent_token\n",
    "df['words'] = word_token\n",
    "df['sentences_qty'] = sent_qty\n",
    "df['words_qty'] = word_qty\n",
    "# sentiment analysis fields\n",
    "df['negative']=neg\n",
    "df['neutral']=neu\n",
    "df['positive']=pos\n",
    "df['compound']=com\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53847 entries, 2 to 60136\n",
      "Data columns (total 16 columns):\n",
      "id                53847 non-null int64\n",
      "text              53847 non-null object\n",
      "name              53847 non-null object\n",
      "episode_name      53847 non-null object\n",
      "episode_number    53847 non-null object\n",
      "season            53847 non-null object\n",
      "ep_seas           53847 non-null object\n",
      "clean_txt         53847 non-null object\n",
      "sentences         53847 non-null object\n",
      "words             53847 non-null object\n",
      "sentences_qty     53847 non-null int64\n",
      "words_qty         53847 non-null int64\n",
      "negative          53847 non-null float64\n",
      "neutral           53847 non-null float64\n",
      "positive          53847 non-null float64\n",
      "compound          53847 non-null float64\n",
      "dtypes: float64(4), int64(3), object(9)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(root_path+'the_office_features.csv', sep=';', encoding='utf-16', index=False)\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
