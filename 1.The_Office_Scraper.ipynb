{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Office - Transcripts Scrapper\n",
    "\n",
    "The purpose of this notebook is to illustrate how The_Office_Scraper.py and IMDB_Scraper.py collects and store the transcripts and ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "The libraries required to run this notebook are Pandas, Numpy and BeautifulSoup.\n",
    "\n",
    "* this notebook will also make use of requests, json, and re (regular expressions), those are standard libraries in python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (1.15.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thiag\\.conda\\envs\\training\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# install required libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function\n",
    "This framework uses 'soups' as objects to handle the webpage content, so we'll use a function to facilitate the colection of this object.\n",
    "\n",
    "To request the webpage data from the server BeautifulSoup uses a get request sent directly from python, since many websites block such requests we need to change our headers to simulate another user agent, such as a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of a webpage and return a list\n",
    "def get_content(url):\n",
    "    # Most websites refuse GET requests from python, so we change the header to pretend we're a browser.\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'}\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect transcripts URLs\n",
    "\n",
    "The transcripts are stored in different pages of the website, in order to access them we'll need a list with their addresses.\n",
    "\n",
    "### PHP REQUESTS\n",
    "The URLs are distributed in lists of 25 items, in 8 pages.\n",
    "to access those pages the website uses a php 'get' request as bellow:\n",
    "\n",
    "    https://transcripts.foreverdreaming.org/viewforum.php?f=574 *first page  \n",
    "    https://transcripts.foreverdreaming.org/viewforum.php?f=574&start=25 *second page  \n",
    "\n",
    "Where **'&start='** is the name of PHP variable beign passed and **25** is the value.\n",
    "\n",
    "### HTML SEARCH\n",
    "Once in the correct page Beautfulsoup will be used to retrieve all anchor(< a>) tags and check if their class name matches with the one we're looking for, python will them store the episode name and the url in lists to be later converted in a dataframe.  \n",
    "Beside the episode transcripts, the list of links in the webpage also have two annoucements from the website that are removed with an exception list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "# web pages:\n",
    "home='https://transcripts.foreverdreaming.org'\n",
    "forum = 'https://transcripts.foreverdreaming.org/viewforum.php?f=574'\n",
    "# php request\n",
    "r = np.arange(25,176,25) # [25, 50, 75 ... 150, 175]\n",
    "lim = '&start='\n",
    "# lists\n",
    "exceptions=['Updated: Editors Needed', 'Online Store']\n",
    "url=[]\n",
    "ep=[]\n",
    "\n",
    "# collect urls from first page\n",
    "page = get_content('https://transcripts.foreverdreaming.org/viewforum.php?f=574')\n",
    "for item in page.find_all('a'):\n",
    "    if(str(item.get('class'))== \"['topictitle']\"):\n",
    "        if item.get_text() not in exceptions:\n",
    "            url.append(home+str(item.get('href'))[1:])\n",
    "            ep.append(item.get_text())\n",
    "            \n",
    "# go trough every value of the range\n",
    "for i in r:\n",
    "    # build php request\n",
    "    page_sulfix = lim+str(i)\n",
    "    forum_list = forum + page_sulfix\n",
    "    # retrieve webpage data\n",
    "    page = get_content(forum_list)\n",
    "    # collect urls\n",
    "    for item in page.find_all('a'):\n",
    "        if(str(item.get('class'))== \"['topictitle']\"):\n",
    "            if item.get_text() not in exceptions:\n",
    "                url.append(home+str(item.get('href'))[1:])\n",
    "                ep.append(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dataframe to hold the episode name and the url\n",
    "df = pd.DataFrame(ep)\n",
    "df.columns = ['ep']\n",
    "df['url'] = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Board Updates: Please Read 8/26/19</td>\n",
       "      <td>https://transcripts.foreverdreaming.org/viewto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01x01 - Pilot</td>\n",
       "      <td>https://transcripts.foreverdreaming.org/viewto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01x02 - Diversity Day</td>\n",
       "      <td>https://transcripts.foreverdreaming.org/viewto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01x03 - Health Care</td>\n",
       "      <td>https://transcripts.foreverdreaming.org/viewto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01x04 - The Alliance</td>\n",
       "      <td>https://transcripts.foreverdreaming.org/viewto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ep  \\\n",
       "0  Board Updates: Please Read 8/26/19   \n",
       "1                       01x01 - Pilot   \n",
       "2               01x02 - Diversity Day   \n",
       "3                 01x03 - Health Care   \n",
       "4                01x04 - The Alliance   \n",
       "\n",
       "                                                 url  \n",
       "0  https://transcripts.foreverdreaming.org/viewto...  \n",
       "1  https://transcripts.foreverdreaming.org/viewto...  \n",
       "2  https://transcripts.foreverdreaming.org/viewto...  \n",
       "3  https://transcripts.foreverdreaming.org/viewto...  \n",
       "4  https://transcripts.foreverdreaming.org/viewto...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Transcripts\n",
    "\n",
    "To facilitate the cleaning process the retrieved data will be organized before beign saved.  \n",
    "The texts from the dialogs are all inside paragraph tags (< p>), and all dialogs start with the name of the character and the dialog as bellow:  \n",
    "  \n",
    "    Character Name: Sentences the character is saying with [interactions and actions the character is performing]  \n",
    "  \n",
    "To break down those dialogs the character name will be separated from the rest by ':', and all the information within '\\[ \\]' will be removed since they're not part of the dialogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board Updates: Please Read 8/26/19\n",
      "01x01 - Pilot\n",
      "01x02 - Diversity Day\n",
      "01x03 - Health Care\n",
      "01x04 - The Alliance\n",
      "01x05 - Basketball\n",
      "01x06 - Hot Girl\n",
      "01x99 - Deleted Scenes from Season 1\n",
      "02x01 - The Dundies\n",
      "02x02 - Sexual Harassment\n",
      "02x03 - Office Olympics\n",
      "02x04 - The Fire\n",
      "02x05 - Halloween\n",
      "02x06 - The Fight\n",
      "02x07 - The Client\n",
      "02x08 - Performance Review\n",
      "02x09 - E-Mail Surveillance\n",
      "02x10 - Christmas Party\n",
      "02x11 - Booze Cruise\n",
      "02x12 - The Injury\n",
      "02x13 - The Secret\n",
      "02x14 - The Carpet\n",
      "02x15 - Boys & Girls\n",
      "02x16 - Valentine's Day\n",
      "02x17 - Dwight's Speech\n",
      "02x18 - Take Your Daughter to Work Day\n",
      "Board Updates: Please Read 8/26/19\n",
      "02x19 - Michael's Birthday\n",
      "02x20 - Drug Testing\n",
      "02x21 - Conflict Resolution\n",
      "02x22 - Casino Night\n",
      "02x99 - Deleted Scenes from Season 2\n",
      "03x00 - The Accountants Webisodes 1-10\n",
      "03x01 - Gay Witch Hunt\n",
      "03x02 - The Convention\n",
      "03x03 - The Coup\n",
      "03x04 - Grief Counseling\n",
      "03x05 - Initiation\n",
      "03x06 - Diwali\n",
      "03x07 - Branch Closing\n",
      "03x08 - The Merger\n",
      "03x09 - The Convict\n",
      "03x10/11 - A Benihana Christmas (Parts 1&2)\n",
      "03x12 - Back from Vacation\n",
      "03x13 - Traveling Salesmen\n",
      "03x14 - The Return\n",
      "03x15 - Ben Franklin\n",
      "03x16 - Phyllis' Wedding\n",
      "03x17 - Business School\n",
      "03x18 - Cocktails\n",
      "03x19 - The Negotiation\n",
      "03x20 - Safety Training\n",
      "Board Updates: Please Read 8/26/19\n",
      "03x21 - Product Recall\n",
      "03x22 - Women's Appreciation\n",
      "03x23 - Beach Games\n",
      "03x24/25 - The Job (Parts 1&2)\n",
      "03x99 - Deleted Scenes from Season 3\n",
      "04x01/02 - Fun Run (Parts 1&2)\n",
      "04x03/04 - Dunder Mifflin Infinity (Parts 1&2)\n",
      "04x05/06 - Launch Party (Parts 1&2)\n",
      "04x07/08 - Money (Parts 1&2)\n",
      "04x09 - Local Ad\n",
      "04x10 - Branch Wars\n",
      "04x11 - Survivor Man\n",
      "04x12 - The Deposition\n",
      "04x13 - Dinner Party\n",
      "04x14 - Chair Model\n",
      "04x15 - Night Out\n",
      "04x16 - Did I Stutter?\n",
      "04x17 - Job Fair\n",
      "04x18/19 - Goodbye, Toby (Parts 1&2)\n",
      "04x99 - Deleted Scenes from Season 4\n",
      "05x00 - Kevin's Loan Webisodes 1-4\n",
      "05x01/02 - Weight Loss (Parts 1&2)\n",
      "05x03 - Business Ethics\n",
      "05x04 - Baby Shower\n",
      "05x05 - Crime Aid\n",
      "Board Updates: Please Read 8/26/19\n",
      "05x06 - Employee Transfer\n",
      "05x07 - Customer Survey\n",
      "05x08 - Business Trip\n",
      "05x09 - Frame Toby\n",
      "05x10 - The Surplus\n",
      "05x11 - Moroccan Christmas\n",
      "05x12 - The Duel\n",
      "05x13 - Prince Family Paper\n",
      "05x14/15 - Stress Relief (Parts 1&2)\n",
      "05x16 - Lecture Circuit (Part 1)\n",
      "05x17 - Lecture Circuit (Part 2)\n",
      "05x18 - Blood Drive\n",
      "05x19 - Golden Ticket\n",
      "05x20 - New Boss\n",
      "05x21 - Two Weeks\n",
      "05x22 - Dream Team\n",
      "05x23 - The Michael Scott Paper Company\n",
      "05x24 - Heavy Competition\n",
      "05x25 - Broke\n",
      "05x26 - Casual Friday\n",
      "05x27 - Cafe Disco\n",
      "05x28 - Company Picnic\n",
      "05x29 - 100 Episodes 100 Moments\n",
      "05x30 - Gag Reel\n",
      "05x99 - Deleted Scenes from Season 5\n",
      "Board Updates: Please Read 8/26/19\n",
      "06x00 - Subtle Sexuality Webisodes 1-3\n",
      "06x01 - Gossip\n",
      "06x02 - The Meeting\n",
      "06x03 - The Promotion\n",
      "06x04/05 - Niagara (Parts 1&2)\n",
      "06x06 - Mafia\n",
      "06x07 - The Lover\n",
      "06x08 - Koi Pond\n",
      "06x09 - Double Date\n",
      "06x10 - Murder\n",
      "06x11 - Shareholder Meeting\n",
      "06x12 - Scott's Tots\n",
      "06x13 - Secret Santa\n",
      "06x14 - The Banker\n",
      "06x15 - Sabre\n",
      "06x16 - The Manager and the Salesman\n",
      "06x17/18 - The Delivery (Parts 1&2)\n",
      "06x19 - St. Patrick's Day\n",
      "06x20 - New Leads\n",
      "06x21 - Happy Hour\n",
      "06x22 - Secretary's Day\n",
      "06x23 - Body Language\n",
      "06x24 - The Cover-Up\n",
      "06x25 - The Chump\n",
      "06x26 - Whistleblower\n",
      "Board Updates: Please Read 8/26/19\n",
      "07x00 - The 3rd Floor Webisodes 1-3\n",
      "07x01 - Nepotism\n",
      "07x02 - Counseling\n",
      "07x03 - Andy's Play\n",
      "07x04 - s*x Ed\n",
      "07x05 - The Sting\n",
      "07x06 - Costume Contest\n",
      "07x07 - Christening\n",
      "07x08 - Viewing Party\n",
      "07x09 - WUPHF.com\n",
      "07x10 - China\n",
      "07x11/12 - Classy Christmas (Parts 1&2)\n",
      "07x13 - Ultimatum\n",
      "07x14 - The Seminar\n",
      "07x15 - The Search\n",
      "07x16 - PDA\n",
      "07x17 - Threat Level Midnight\n",
      "07x18 - Todd Packer\n",
      "07x19 - Garage Sale\n",
      "07x20 - Training Day\n",
      "07x21 - Michael's Last Dundies\n",
      "07x22 - Goodbye, Michael\n",
      "07x23 - The Inner Circle\n",
      "07x24 - Dwight K. Schrute, (Acting) Manager\n",
      "07x25/26 - Search Committee (Parts 1&2)\n",
      "Board Updates: Please Read 8/26/19\n",
      "08x01 - The List\n",
      "08x02 - The Incentive\n",
      "08x03 - Lotto\n",
      "08x04 - Garden Party\n",
      "08x05 - Spooked\n",
      "08x06 - Doomsday\n",
      "08x07 - Pam's Replacement\n",
      "08x08 - Gettysburg\n",
      "08x09 - Mrs. California\n",
      "08x10 - Christmas Wishes\n",
      "08x11 - Trivia\n",
      "08x12 - Pool Party\n",
      "08x13 - Jury Duty\n",
      "08x14 - Special Project\n",
      "08x15 - Tallahassee\n",
      "08x16 - After Hours\n",
      "08x17 - Test The Store\n",
      "08x18 - Last Day In Florida\n",
      "08x19 - Get The Girl\n",
      "08x20 - Welcome Party\n",
      "08x21 - Angry Andy\n",
      "08x22 - Fundraiser\n",
      "08x23 - Turf War\n",
      "08x24 - Free Family Portrait Studio\n",
      "08x99 - Deleted Scenes from Season 8\n",
      "Board Updates: Please Read 8/26/19\n",
      "09x01 - The New Guys\n",
      "09x02 - Roy's Wedding\n",
      "09x03 - Andy's Ancestry\n",
      "09x04 - Work Bus\n",
      "09x05 - Here Comes Treble\n",
      "09x06 - The Boat\n",
      "09x07 - The Whale\n",
      "09x08 - The Target\n",
      "09x09 - Dwight Christmas\n",
      "09x10 - Lice\n",
      "09x11 - Suit Warehouse\n",
      "09x12 - Customer Loyalty\n",
      "09x13 - Junior Salesman\n",
      "09x14 - Vandalism\n",
      "09x15 - Couples Discount\n",
      "09x16 - Moving On\n",
      "09x17 - The Farm\n",
      "09x18 - Promos\n",
      "09x19 - Stairmageddon\n",
      "09x20 - Paper Airplane\n",
      "09x21 - Livin' the Dream\n",
      "09x22/23 - A.A.R.M\n",
      "09x24/25 - Finale\n",
      "09x26 - Retrospective\n"
     ]
    }
   ],
   "source": [
    "char=[]\n",
    "text=[]\n",
    "ep=[]\n",
    "\n",
    "# go trough all urls previously collected\n",
    "for i, row in df.iterrows():\n",
    "    # retrieve webpage and print episode name\n",
    "    page = get_content(row.url)\n",
    "    print(row.ep)\n",
    "    # go trough the paragraphs check if they contain ':' and remove text inside []\n",
    "    for item in page.find_all('p'):\n",
    "        if(':' in item.get_text()):\n",
    "            temp = item.get_text().split(':',1)\n",
    "            char.append(re.sub(\"[\\[].*?[\\]]\", \"\", temp[0]))\n",
    "            text.append(re.sub(\"[\\[].*?[\\]]\", \"\", temp[1]))\n",
    "            ep.append(row.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Dataframe\n",
    "df_lines = pd.DataFrame(char)\n",
    "df_lines.columns = ['char']\n",
    "df_lines['text'] = text\n",
    "df_lines['ep'] = ep\n",
    "# Remove blank lines\n",
    "df_lines = df_lines.drop(df_lines[df_lines['text']==' '].index).copy()\n",
    "df_lines = df_lines.drop(df_lines[df_lines['text']==''].index).copy()\n",
    "df_lines = df_lines[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save .csv file\n",
    "df_lines.to_csv('the_office.csv', sep=';', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "relations = []\n",
    "talk = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # print progress\n",
    "    counter += 1\n",
    "    if counter % 20 == 0:\n",
    "        print(counter/2,'%')\n",
    "    # collect data\n",
    "    page = get_content(row.url)\n",
    "    for item in page.find_all(['p','hr']):\n",
    "        if item.name == 'p':\n",
    "            if(':' in item.get_text()):\n",
    "                temp = item.get_text().split(':',1)\n",
    "                talk.append(re.sub(\"[\\[].*?[\\]]\", \"\", temp[0]))\n",
    "        else:\n",
    "            relations.append(talk)\n",
    "            talk = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('corrections.json')\n",
    "corrections_json = file.read()\n",
    "corrections = json.loads(corrections_json)\n",
    "\n",
    "main_chars = ['Darryl', 'Creed', 'Meredith', 'Kelly', 'Ryan Howard', 'Stanley',\n",
    "              'Phyllis', 'Oscar', 'Andy', 'Angela', 'Kevin', 'Pam', 'Jim',\n",
    "              'Dwight', 'Michael']\n",
    "\n",
    "totals = []\n",
    "talk_scores = {}\n",
    "\n",
    "for talk in relations:\n",
    "    for name in talk:\n",
    "        n = name\n",
    "        if name in corrections:\n",
    "            name = corrections[name]\n",
    "        if name in main_chars:    \n",
    "            talk_scores[name] = talk.count(n)\n",
    "    if(len(talk_scores) > 1):\n",
    "        totals.append(talk_scores)\n",
    "    talk_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4463\n"
     ]
    }
   ],
   "source": [
    "# check if there is any missing character and print their names\n",
    "for name in main_chars:\n",
    "    flag = True\n",
    "    for talk in totals:\n",
    "        if name in talk:\n",
    "            flag = False\n",
    "    if flag:\n",
    "        print(name)\n",
    "# print number of conversations\n",
    "print(len(totals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a .json file\n",
    "with open('conversations.json', 'w') as file:\n",
    "    json.dump(totals, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Ratings\n",
    "Very similar to what was done to the transcripts but simpler, in order to retrieve the ratings from IMDB the same methods and libraries will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection\n",
    "The script loop trought the webpages for every season, saving the collected data in temporary lists that are merged into the main lists at the end of each loop. Those lists are converted into dataframes later.\n",
    "\n",
    "### Episode Rating\n",
    "The ratings are stored in a span tag with class 'ipl-rating-star__rating', this same combination is used for their voting system so BeutifulSoup is retrieving lots of irrelevant values. The actual value of the ratings apear every 23th value and that is what the program collect.\n",
    "\n",
    "### Episode Name\n",
    "The episode names are retrieved from anchor tags where the attribute 'itemprop' is equal name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, ep_name, ep_num, season = [],[],[],[]\n",
    "\n",
    "# go trought each season page\n",
    "for s in np.arange(1,10):\n",
    "    temp_ratings, temp_ep_name, temp_ep_num, temp_season = [],[],[],[]\n",
    "    page = get_content('https://www.imdb.com/title/tt0386676/episodes?season='+str(s))\n",
    "    counter = 1\n",
    "    \n",
    "    # get the ratings from span tags\n",
    "    for i in page.find_all('span'):\n",
    "        class_name = dict(i.attrs).get('class')\n",
    "        if(class_name == ['ipl-rating-star__rating']):\n",
    "            temp_ratings.append(i.get_text())\n",
    "    # get just the rating values    \n",
    "    temp_ratings = temp_ratings[::23]\n",
    "    \n",
    "    # get the episode name from the anchor tags\n",
    "    for i in page.find_all('a'):\n",
    "        class_name = dict(i.attrs).get('itemprop')\n",
    "        if(class_name == 'name'):\n",
    "            temp_ep_name.append(i.get_text())\n",
    "            temp_ep_num.append(counter)\n",
    "            temp_season.append(s)\n",
    "            counter += 1\n",
    "    # add data to         \n",
    "    ratings.extend(temp_ratings)\n",
    "    ep_name.extend(temp_ep_name)\n",
    "    ep_num.extend(temp_ep_num)\n",
    "    season.extend(temp_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_name</th>\n",
       "      <th>ep_num</th>\n",
       "      <th>season</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diversity Day</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health Care</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Alliance</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basketball</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep_name  ep_num  season ratings\n",
       "0          Pilot       1       1     7.5\n",
       "1  Diversity Day       2       1     8.3\n",
       "2    Health Care       3       1     7.9\n",
       "3   The Alliance       4       1     8.1\n",
       "4     Basketball       5       1     8.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dataframe\n",
    "df = pd.DataFrame(ep_name)\n",
    "df.columns = ['ep_name']\n",
    "df['ep_num'] = ep_num\n",
    "df['season'] = season\n",
    "df['ratings'] = ratings\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save .csv with the ratings per episode\n",
    "df.to_csv('ratings.csv', sep=';', encoding='utf-16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
